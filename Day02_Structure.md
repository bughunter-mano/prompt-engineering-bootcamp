# Day 2 — Prompt Structures (Role • Task • Context • Format)
**Cheat‑sheet:** 
- Role: Who is the model pretending to be?  
- Task: What exactly should it do?  
- Context: Background, constraints, examples, audience.  
- Format: Exact output format (bullets, JSON, table, steps).  

## Copy‑Paste Structured Prompt
You are an **AI technical writer**.
**Task:** Summarize the following text for a non‑technical audience.
**Context:** Keep it accurate, remove jargon, keep to 120–150 words, use bullets.
**Format:** Return exactly:
- 3 bullet points
- 1 one‑sentence takeaway
- 3 relevant hashtags

**Text to summarize:** 
"""
Artificial Intelligence models generate outputs based on probabilities learned from data.
They are powerful but can hallucinate, so we must structure prompts, provide context, and request explicit formats.
Engineered prompts reduce ambiguity and improve reliability.
"""

## Paste Your Result Below
- 3 bullets: . These AI models work by guessing the most likely next word, like a highly advanced autocomplete.

.The models can sometimes make up information or get facts wrong, a behavior known as "hallucination."

.You can get more reliable answers by providing clear instructions and specific examples, a technique called "prompt engineering.
- Takeaway:Giving an AI clear and detailed instructions helps it provide a more accurate and useful response.
- Hashtags:#AI #PromptEngineering #LargeLanguageModels

## Mini Reflection (2–3 lines)
What changed when you specified Role/Task/Context/Format?
Mini Reflection

When I was given the specific Role/Task/Context/Format, my response became much more focused and accurate. The constraints of a defined persona ("AI technical writer"), a clear goal ("summarize"), a specific audience and word count ("non-technical audience, 120–150 words"), and a strict output structure ("3 bullet points, 1 takeaway, 3 hashtags") guided me to produce a response that precisely matched the user's request, avoiding any unnecessary or out-of-scope information.
